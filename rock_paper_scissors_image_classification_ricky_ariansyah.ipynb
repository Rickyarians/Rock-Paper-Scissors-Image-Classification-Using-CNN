{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Rock Paper Scissor Image Classification\n",
        "\n",
        "oleh : Ricky Ariansyah \n",
        "\n",
        "email : rickyarians@outlook.com\n",
        "\n",
        "Dataset : Rock Paper Scissors\n",
        "Total Images : 2188\n",
        "Rock : 726 | Paper : 712 | Scissors : 750\n",
        "\n",
        "Accuracy\n",
        "\n",
        " Acc : 93%"
      ],
      "metadata": {
        "id": "mUVSBsMdVShN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tahapan\n",
        "\n",
        "- memastikan library yang akan dipakai\n",
        "\n",
        "- Mengunduh dataset dan melakukan extract file dengan metode unzip.\n",
        "\n",
        "- Menampung direktori setiap kelas pada direktori train dan validasi ke dalam variabel.\n",
        "\n",
        "- Pre-processing data dengan image augmentation.\n",
        "\n",
        "- Mempersiapkan data latih yang akan dipelajari oleh model.\n",
        "\n",
        "- Membangun arsitektur model dengan Convolutional Neural Network (CNN).\n",
        "- Compile dan latih model dengan model.compile dan model.fit hingga mendapatkan akurasi yang diinginkan.\n",
        "\n",
        "- Menguji model yang telah dibuat dengan menggunakan gambar yang belum dikenali oleh model."
      ],
      "metadata": {
        "id": "PDoXrTaDV9_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kriteria Submission\n",
        "\n",
        "- [x] Dataset yang dipakai haruslah dataset berikut : rockpaperscissors, atau gunakan link ini pada wget command: https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip.\n",
        "- Dataset harus dibagi menjadi train set dan validation set.\n",
        "- Ukuran validation set harus 40% dari total dataset (data training memiliki 1314 sampel, dan data validasi sebanyak 874 sampel).\n",
        "- Harus mengimplementasikan augmentasi gambar.\n",
        "- Menggunakan image data generator.\n",
        "- Model harus menggunakan model sequential.\n",
        "- Pelatihan model tidak melebihi waktu 30 menit.\n",
        "- Program dikerjakan pada Google Colaboratory.\n",
        "- Akurasi dari model minimal 85%."
      ],
      "metadata": {
        "id": "HRtmUOJcWSf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Library yang dibutuhkan"
      ],
      "metadata": {
        "id": "_FbuoQ87WtLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# library untuk prroses file berbentuk zip\n",
        "import zipfile\n",
        "# library menggunakan fungsi operating system\n",
        "import os\n",
        "import time\n",
        "\n",
        "# library machine learning tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# libarary tambahan untuk visualisasi, proses image, proses data dan google colab\n",
        "import keras.utils as image\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "pN3uF35gWSEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "oh7E8cyoimra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset menggunakan wget\n",
        "!wget https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip"
      ],
      "metadata": {
        "id": "eDRcCdI4nyFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip / Ekstrak Dataset\n",
        "\n",
        "ekstrak dataset yang telah didownload menggunakan library zipfile"
      ],
      "metadata": {
        "id": "nxSVyTQ1itd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ekstrak file tipe zip\n",
        "ekstrak_zip = 'rockpaperscissors.zip'\n",
        "out_zip = zipfile.ZipFile(ekstrak_zip, 'r')\n",
        "# ekstrak ke dalam folder dataset\n",
        "out_zip.extractall('/dataset')\n",
        "out_zip.close()"
      ],
      "metadata": {
        "id": "hdjIBpAGiqSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Atur Lokasi Direktori Dataset RockPaperScissors\n",
        "\n",
        "atur lokasi direktori dan masukkan ke dalam variabel untuk mempermudah pemanggilan dataset"
      ],
      "metadata": {
        "id": "gUtqjRsMjRHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_dataset = \"/dataset/rockpaperscissors/rps-cv-images\"\n",
        "dir_paper = os.path.join(\"/dataset/rockpaperscissors/rps-cv-images/paper\")\n",
        "dir_rock = os.path.join(\"/dataset/rockpaperscissors/rps-cv-images/rock\")\n",
        "dir_scissors = os.path.join(\"/dataset/rockpaperscissors/rps-cv-images/scissors\")"
      ],
      "metadata": {
        "id": "WXBxwQ49jQ7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cek hasil ekstrak"
      ],
      "metadata": {
        "id": "f7v8oEhzjkFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from posix import listdir\n",
        "print(f\"{listdir('/dataset/rockpaperscissors')}\")"
      ],
      "metadata": {
        "id": "WkEOqFVXorX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cek total data"
      ],
      "metadata": {
        "id": "Aqd-5Fvro60D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cek total data\n",
        "\n",
        "\n",
        "print(f\"Total Data Image paper : {len(os.listdir(dir_paper))}\")\n",
        "print(f\"Total Data Image rock : {len(os.listdir(dir_rock))}\")\n",
        "print(f\"Total Data Image scissors : {len(os.listdir(dir_scissors))}\")\n",
        "\n",
        "print(f\"Total Data Image keseluruhan {len(os.listdir(dir_paper)) + len(os.listdir(dir_rock)) + len(os.listdir(dir_scissors))}\")"
      ],
      "metadata": {
        "id": "FWuL0VHwizg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image data generator\n",
        "\n",
        "\n",
        "kita akan menerapkan ImageDataGenerator untuk data latih dan data validasi. "
      ],
      "metadata": {
        "id": "JrVfww42ocbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# deklarasi variabel size validasi sesuai ketentuan sebanyak 40%\n",
        "val_size = 0.4\n",
        "\n",
        "Train_datagen = ImageDataGenerator(\n",
        "    rotation_range = 30,\n",
        "    brightness_range = [0.2,1.0],\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = \"nearest\",\n",
        "    rescale = 1./255,\n",
        "    validation_split = val_size\n",
        ")\n",
        "\n",
        "Validation_datagen = ImageDataGenerator(\n",
        "    rotation_range = 30,\n",
        "    brightness_range = [0.2,1.0],\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = \"nearest\",\n",
        "    rescale = 1./255,\n",
        "    validation_split = val_size\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "VZxea6bInwUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Dataset\n",
        "\n",
        "Ukuran validation set harus 40% dari total dataset (data training memiliki 1314 sampel, dan data validasi sebanyak 874 sampel)."
      ],
      "metadata": {
        "id": "V3F9udcnpzOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hasil split dataset dengan \n",
        "# Train : 1314 | Validation :  874\n",
        "\n",
        "# Mengatur lebar dan tinggi gambar\n",
        "img_width = 150\n",
        "img_height = 150\n",
        "\n",
        "# Train dan Validation generator  dengan mode categorical karena klasifikasi ini lebih dari 2\n",
        "Train_generator = Train_datagen.flow_from_directory(\n",
        "    dir_dataset,\n",
        "    target_size = (img_width,img_height),\n",
        "    color_mode = \"rgb\",\n",
        "    class_mode = \"categorical\",\n",
        "    batch_size = 16,\n",
        "    shuffle = True,\n",
        "    subset = \"training\"\n",
        ")\n",
        "\n",
        "Validation_generator = Validation_datagen.flow_from_directory(\n",
        "    dir_dataset,\n",
        "    target_size = (img_width,img_height),\n",
        "    color_mode = \"rgb\",\n",
        "    class_mode = \"categorical\",\n",
        "    batch_size = 16,\n",
        "    shuffle = False,\n",
        "    subset = \"validation\"\n",
        ")"
      ],
      "metadata": {
        "id": "C1Q7D5lXpPnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pembuatan Model dengan tipe Sequential\n",
        "\n",
        "Model = Sequential(\n",
        "    [\n",
        "     Conv2D(32, (3,3), strides = (1,1), activation = 'relu' , input_shape = (img_width,img_height,3)),\n",
        "     MaxPooling2D(pool_size = (2,2), padding = 'valid'),\n",
        "     Conv2D(64, (3,3), strides = (1,1), activation = 'relu' ),\n",
        "     MaxPooling2D(pool_size = (2,2), padding = 'valid'),\n",
        "     Conv2D(128, (3,3), strides = (1,1), activation = 'relu' ),\n",
        "     MaxPooling2D(pool_size = (2,2), padding = 'valid'),\n",
        "     Flatten(),\n",
        "     Dropout(0.2),\n",
        "     Dense(128, activation = 'relu'),\n",
        "     Dense(3, activation='softmax')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "gwkuBZSEpts3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Penggunaan Optimizer 'Adam'\n",
        "Adam(name='Adam')\n",
        "Model.compile(optimizer = 'Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "upH608BBuAmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Penggunaan Callbacks dengan fungsi EarlyStopping dengan memonitoring Val_Loss\n",
        "callback = EarlyStopping(\n",
        "    monitor = 'val_loss',\n",
        "    min_delta = 0.001,\n",
        "    patience = 3,\n",
        "    verbose = 1,\n",
        "    mode = 'auto'\n",
        ")\n",
        "start = time.time()\n",
        "Model.fit(\n",
        "    Train_generator,\n",
        "    epochs = 10,\n",
        "    validation_data = Validation_generator,\n",
        "    callbacks=[callback]\n",
        ")\n",
        "stop = time.time()\n",
        "print(f\"Training time: {round((stop - start)/60)}minute\")\n",
        "     "
      ],
      "metadata": {
        "id": "rqJoNfXVuCyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fungsi kondisi\n",
        "\n",
        "def predict_image(image):\n",
        "    classes = Model.predict(images, batch_size=16)\n",
        "    print(\"\\n\")\n",
        "    print('Hasil Prediksi : ',classes[0],'\\n')\n",
        "\n",
        "    if classes[0][0] == 1:\n",
        "      print('Hasil Gambar : Paper')\n",
        "    elif classes[0][1] == 1:\n",
        "      print('Hasil Gambar : Rock')\n",
        "    else:\n",
        "      print('Hasil Gambar : Scissor')\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "kxE3rH8buFbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload File ke google colabs\n",
        "uploaded = files.upload()\n",
        "\n",
        "for file_upload in uploaded.keys():\n",
        "\n",
        "  path = file_upload\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  # Membuat numpy vstack array untuk hasil prediksi \n",
        "  images = np.vstack([x])\n",
        " \n",
        "  predict_image(images)"
      ],
      "metadata": {
        "id": "oFfqd6x01tJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HIo8R3iJ-SOS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}